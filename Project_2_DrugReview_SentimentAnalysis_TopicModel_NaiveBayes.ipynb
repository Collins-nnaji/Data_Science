{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1qV-h0NsDNX8uWUVw4hF-kJQirWkE55zP",
      "authorship_tag": "ABX9TyNqsnOsxb37d7f/BqFh1vXI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Collins-nnaji/Data_Science/blob/main/Project_2_DrugReview_SentimentAnalysis_TopicModel_NaiveBayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "goN_xqBJZfXJ"
      },
      "outputs": [],
      "source": [
        "path = \"/content/drive/MyDrive/Colab Notebooks/Drug_Review_Train.tsv\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wordcloud scikit-learn\n",
        "!pip install textblob\n",
        "!pip install gensim nltk pandas\n",
        "!python -m spacy download en_core_web_sm\n",
        "!pip install spacy\n",
        "!pip install gensim sklearn pandas\n",
        "!pip install pyLDAvis\n",
        "!pip install matplotlib\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import gensim\n",
        "import seaborn as sns\n",
        "import pyLDAvis.gensim_models\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from textblob import TextBlob\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from gensim import corpora\n",
        "from gensim.models import LdaModel, CoherenceModel\n",
        "from wordcloud import WordCloud\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n"
      ],
      "metadata": {
        "id": "5usmTSBScXm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1. READ FILE,from text format to dataframe\n",
        "\n",
        "df = pd.read_csv(path, sep='\\t')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "MqrQZaoraQ6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2. SENTIMENT ANALYSIS USING TEXTBLOB\n",
        "\n",
        "# Function to get the sentiment\n",
        "def get_sentiment(text):\n",
        "    # Create a TextBlob object\n",
        "    analysis = TextBlob(str(text))\n",
        "\n",
        "    # Classifying the polarity of the text\n",
        "    if analysis.sentiment.polarity > 0:\n",
        "        return 'positive', analysis.sentiment.polarity\n",
        "    elif analysis.sentiment.polarity == 0:\n",
        "        return 'neutral', analysis.sentiment.polarity\n",
        "    else:\n",
        "        return 'negative', analysis.sentiment.polarity\n",
        "\n",
        "# Applying the function to the reviews to get sentiments and scores\n",
        "df['benefitsSentiment'], df['benefitsSentimentScore'] = zip(*df['benefitsReview'].apply(get_sentiment))\n",
        "df['sideEffectsSentiment'], df['sideEffectsSentimentScore'] = zip(*df['sideEffectsReview'].apply(get_sentiment))\n",
        "df['commentsSentiment'], df['commentsSentimentScore'] = zip(*df['commentsReview'].apply(get_sentiment))"
      ],
      "metadata": {
        "id": "_aQis7ks7J_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. VIEW DATA IN DIFFERENT COLUMN COMBINATIONS\n",
        "df.head(20)"
      ],
      "metadata": {
        "id": "bkLpI4_9wv38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "benefits_data = df[['benefitsReview', 'benefitsSentiment', 'benefitsSentimentScore']]\n",
        "benefits_data"
      ],
      "metadata": {
        "id": "3PjKzWmyxE-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "side_effects_data = df[['sideEffectsReview', 'sideEffectsSentiment', 'sideEffectsSentimentScore']]\n",
        "side_effects_data"
      ],
      "metadata": {
        "id": "068qvqjL5y3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comments_data = df[['commentsReview', 'commentsSentiment', 'commentsSentimentScore']]\n",
        "comments_data"
      ],
      "metadata": {
        "id": "cCmjLEMd5y6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "side_effects_data2 = df[['sideEffectsReview', 'sideEffectsSentiment', 'sideEffectsSentimentScore','rating','effectiveness','sideEffects']]\n",
        "side_effects_data2"
      ],
      "metadata": {
        "id": "lHb0KMmU5y9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comments_data2 = df[['commentsReview', 'commentsSentiment', 'commentsSentimentScore','rating','effectiveness','sideEffects']]\n",
        "comments_data2"
      ],
      "metadata": {
        "id": "Ym_5jW_N5zAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "benefits_data2 = df[['benefitsReview', 'benefitsSentiment', 'benefitsSentimentScore','rating','effectiveness','sideEffects']]\n",
        "benefits_data2"
      ],
      "metadata": {
        "id": "PQhvAXuX5zCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['effectiveness'].unique()"
      ],
      "metadata": {
        "id": "-bl51K708Qs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['urlDrugName'].unique()"
      ],
      "metadata": {
        "id": "uUXq_cm2GKbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['sideEffects'].unique()"
      ],
      "metadata": {
        "id": "NnlLyrUfGKfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6. TOPIC MODELLING FOR CONCATENATED REVIEWS\n",
        "\n",
        "# 1. Preprocessing\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "def preprocess(text):\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [token for token in tokens if token.lower() not in stop_words]\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    return tokens\n",
        "# Aggregating the textual data columns (ensuring all are strings)\n",
        "df['agg_review'] = df['benefitsReview'].astype(str) + ' ' + df['sideEffectsReview'].astype(str) + ' ' + df['commentsReview'].astype(str)\n",
        "# Applying preprocessing on the aggregated reviews\n",
        "df['tokens'] = df['agg_review'].apply(preprocess)\n",
        "\n",
        "# 2. Data Aggregation (using each review as a separate document here)\n",
        "texts = df['tokens'].tolist()\n",
        "\n",
        "# 3. & 4. Model Selection & Determine Topic Count\n",
        "# Create a dictionary and a corpus for LDA\n",
        "dictionary = corpora.Dictionary(texts)\n",
        "corpus = [dictionary.doc2bow(text) for text in texts]\n",
        "# Set the number of topics\n",
        "num_topics = 10\n",
        "\n",
        "# 5. Topic Modeling using LDA\n",
        "lda_model = LdaModel(corpus=corpus, num_topics=num_topics, id2word=dictionary, passes=15)\n",
        "\n",
        "# 6. Model Evaluation using Coherence Score\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('Coherence Score: ', coherence_lda)\n"
      ],
      "metadata": {
        "id": "ecVPIx3wLCpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary, mds='mmds', n_jobs=1)\n",
        "    pyLDAvis.display(vis)"
      ],
      "metadata": {
        "id": "ZPDQnMGDLDxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. DATA VISUALIZATIONS\n",
        "# Word Cloud for benefitsReview\n",
        "all_reviews1 = ' '.join(df['benefitsReview'].astype(str))\n",
        "wordcloud = WordCloud(stopwords=ENGLISH_STOP_WORDS, background_color=\"white\", max_words=100, width=800, height=400).generate(all_reviews1)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('Word Cloud for Benefits Review')\n",
        "plt.show()\n",
        "\n",
        "# 2. Word Cloud for sideEffectsReview\n",
        "all_reviews2 = ' '.join(df['sideEffectsReview'].astype(str))\n",
        "wordcloud = WordCloud(stopwords=ENGLISH_STOP_WORDS, background_color=\"white\", max_words=100, width=800, height=400).generate(all_reviews2)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('Word Cloud for sideEffectsReview')\n",
        "plt.show()\n",
        "\n",
        "# 3. Word Cloud for commentsReview\n",
        "all_reviews3 = ' '.join(df['commentsReview'].astype(str))\n",
        "wordcloud = WordCloud(stopwords=ENGLISH_STOP_WORDS, background_color=\"white\", max_words=100, width=800, height=400).generate(all_reviews3)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('Word Cloud for commentsReview')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RdqNGpGJskSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(data=df, x='rating')\n",
        "plt.title('Distribution of Ratings')\n",
        "plt.xlabel('Rating')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "CSR4ptwiQ9kT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(data=df, y='effectiveness', order=df['effectiveness'].value_counts().index)\n",
        "plt.title('Distribution of Effectiveness Ratings')\n",
        "plt.xlabel('Count')\n",
        "plt.ylabel('Effectiveness')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wLB06vTDQ9pK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(data=df, y='sideEffects', order=df['sideEffects'].value_counts().index)\n",
        "plt.title('Distribution of Reported Side Effects')\n",
        "plt.xlabel('Count')\n",
        "plt.ylabel('Side Effects')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wumbMTtBQ9sK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. TEXT CLASSIFICATION\n",
        "# Grouping the effectiveness into two classes\n",
        "\n",
        "df['benefitsReview'].fillna('', inplace=True)\n",
        "df['effectiveness'] = df['effectiveness'].replace({\n",
        "    'Highly Effective': 'Effective',\n",
        "    'Considerably Effective': 'Effective',\n",
        "    'Moderately Effective': 'Effective',\n",
        "    'Marginally Effective': 'Ineffective',\n",
        "    'Ineffective': 'Ineffective'\n",
        "})\n",
        "\n",
        "# Splitting data\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['benefitsReview'], df['effectiveness'], test_size=0.25, random_state=42)\n",
        "\n",
        "# Vectorizing benefitsReview\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X_train_tf = vectorizer.fit_transform(X_train)\n",
        "X_test_tf = vectorizer.transform(X_test)\n",
        "\n",
        "# Label encoding effectiveness\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# Classifier\n",
        "clf = MultinomialNB().fit(X_train_tf, y_train_encoded)\n",
        "predictions = clf.predict(X_test_tf)\n",
        "\n",
        "# Print Accuracy\n",
        "print(\"Accuracy:\", accuracy_score(y_test_encoded, predictions))\n",
        "\n",
        "# Classification Report\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_encoded, predictions, target_names=label_encoder.classes_))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test_encoded, predictions)\n",
        "\n",
        "# Visualizing Confusion Matrix\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.heatmap(cm, annot=True, cmap=\"YlGnBu\", fmt='g', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "0-Qp0GX5QoEu",
        "outputId": "ee82109e-242b-4001-c318-6ec5b862f758"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-de0f510bec21>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Grouping the effectiveness into two classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'benefitsReview'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m df['effectiveness'] = df['effectiveness'].replace({\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m'Highly Effective'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Effective'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    }
  ]
}